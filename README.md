# Awesome Attention [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of research papers, surveys, and resources on **Attention Mechanisms** across different domains — Computer Vision, NLP, Speech, Graphs, Multi-modal Learning, Medical Imaging, and more.  
This repository organizes papers into categories, each with a structured table:

**Title | Authors | Venue | Year | Paper Link**

---

## 📑 Table of Contents
1. [Channel Attention](channel_attention.md)
2. [Spatial Attention](spatial_attention.md)
3. [Temporal Attention](temporal_attention.md)
4. [Channel + Spatial Attention](channel_spatial_attention.md)
5. [Transformer-based Attention](transformer_attention.md)
6. [Graph Attention](graph_attention.md)
7. [Speech & Audio Attention](speech_audio_attention.md)
8. [Multi-modal Attention](multi_modal_attention.md)
9. [Medical Imaging Attention](medical_attention.md)
10. [Surveys & Reviews](surveys.md)
11. [Miscellaneous / Domain-specific](misc_attention.md)

---

## 📂 Categories Overview

### 1. Channel Attention
Papers focusing on improving **feature channel representation** via re-weighting or recalibration strategies.  
📄 **Examples:** Squeeze-and-Excitation Networks (CVPR 2018), ECA-Net (CVPR 2020).

➡️ [View List](channel_attention.md)

---

### 2. Spatial Attention
Papers that enhance **spatial feature maps** by attending to important regions in the input.  
📄 **Examples:** Show, Attend and Tell (ICML 2015), CBAM (ECCV 2018).

➡️ [View List](spatial_attention.md)

---

### 3. Temporal Attention
Methods for **time-dependent data** such as video sequences, time-series, and sequential prediction tasks.  
📄 **Examples:** Jointly Attentive Spatial-Temporal Pooling (ICCV 2017).

➡️ [View List](temporal_attention.md)

---

### 4. Channel + Spatial Attention
Hybrid attention modules combining both **channel** and **spatial** weighting.  
📄 **Examples:** CBAM (ECCV 2018), DANet (CVPR 2019).

➡️ [View List](channel_spatial_attention.md)

---

### 5. Transformer-based Attention
Papers leveraging **self-attention** and **transformer architectures** for vision, NLP, speech, and multi-modal tasks.  
📄 **Examples:** Attention Is All You Need (NeurIPS 2017), Vision Transformer (ICLR 2021).

➡️ [View List](transformer_attention.md)

---

### 6. Graph Attention
Attention applied to **graph-structured data** for node/edge/graph-level prediction tasks.  
📄 **Examples:** Graph Attention Networks (ICLR 2018), GATv2.

➡️ [View List](graph_attention.md)

---

### 7. Speech & Audio Attention
Methods for **speech recognition, speaker identification, and audio event detection**.  
📄 **Examples:** Attention-based End-to-End Speech Recognition (ICASSP 2016).

➡️ [View List](speech_audio_attention.md)

---

### 8. Multi-modal Attention
Techniques combining **vision, language, audio, or other modalities** using attention.  
📄 **Examples:** Bottom-Up and Top-Down Attention for VQA (CVPR 2018).

➡️ [View List](multi_modal_attention.md)

---

### 9. Medical Imaging Attention
Attention in **medical image segmentation, detection, and diagnosis**.  
📄 **Examples:** Attention U-Net (MIDL 2018), CA-Net (TMI 2021).

➡️ [View List](medical_attention.md)

---

### 10. Surveys & Reviews
Survey papers summarizing the progress of attention mechanisms.  
📄 **Examples:** An Attentive Survey of Attention Models (ACM TIST 2021).

➡️ [View List](surveys.md)

---

### 11. Miscellaneous / Domain-specific
Attention methods in **recommendation systems, finance, remote sensing, etc.**

➡️ [View List](misc_attention.md)

---

## 🤝 Contributing
We welcome contributions!  
If you know of a new paper, dataset, or codebase related to **attention mechanisms**, please:

1. Check the relevant category `.md` file.
2. Add a new row in the format:

