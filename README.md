# Awesome Attention [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of research papers, surveys, and resources on **Attention Mechanisms** across different domains ‚Äî Computer Vision, NLP, Speech, Graphs, Multi-modal Learning, Medical Imaging, and more.  
This repository organizes papers into categories, each with a structured table:

**Title | Authors | Venue | Year | Paper Link**

---

## üìë Table of Contents
1. [Channel Attention](channel_attention.md)
2. [Spatial Attention](spatial_attention.md)
3. [Temporal Attention](temporal_attention.md)
4. [Channel + Spatial Attention](channel_spatial_attention.md)
5. [Transformer-based Attention](transformer_attention.md)
6. [Graph Attention](graph_attention.md)
7. [Speech & Audio Attention](speech_audio_attention.md)
8. [Multi-modal Attention](multi_modal_attention.md)
9. [Medical Imaging Attention](medical_attention.md)
10. [Surveys & Reviews](surveys.md)
11. [Miscellaneous / Domain-specific](misc_attention.md)

---

# Channel Attention ‚Äî Awesome Attention

Papers that focus on channel-wise recalibration, feature re-weighting and channel attention modules.

> Table columns: **Title | Authors | Venue | Year | Paper Link**

| Title | Authors | Venue | Year | Paper Link |
|---|---|---:|---:|---|
| Squeeze-and-Excitation Networks | J. Hu, L. Shen, G. Sun | CVPR | 2018 | []() |
| RCAN: Image Super-Resolution Using Very Deep Residual Channel Attention Networks | Y. Zhang et al. | ECCV | 2018 | []() |
| ECA-Net: Efficient Channel Attention | Q. Wang et al. | CVPR | 2020 | []() |
| GSoPNet: Global Second-order Pooling Conv Nets | Y. Li et al. | CVPR | 2019 | []() |
| SRM: Style-based Recalibration Module | J. Rony et al. | ICCV | 2019 | []() |
| DIANet: Dense-and-Implicit Attention Network | M. India et al. | AAAI | 2020 | []() |
| Competitive-SENet | ‚Äî | CoRR | 2018 | []() |
| FcaNet: Frequency Channel Attention Networks | Z. Li et al. | ICCV | 2021 | []() |
| ResNeSt: Split-Attention Networks | H. Zhang et al. | CoRR | 2020 | []() |
| SGE: Spatial Group-wise Enhance (channel-centric variant) | W. Hu et al. | arXiv | 2019 | []() |
| SCSE: Concurrent Spatial and Channel ‚ÄòSqueeze & Excitation‚Äô | ‚Äî | MICCAI | 2018 | []() |
| SENet (PAMI version) | J. Hu, L. Shen, G. Sun | PAMI | 2019 | []() |
| Gated Channel Transformation for Visual Recognition | ‚Äî | CVPR | 2020 | []() |
| Channel-wise Attention for Image Restoration (RNAN-style) | ‚Äî | ICLR / arXiv | 2019 | []() |
| Tiled Squeeze-and-Excite (local channel attention) | ‚Äî | ICCV Workshop | 2021 | []() |
| SRM (alternate) applications | ‚Äî | ICML/ICCV workshops | 2019 | []() |
| Competitive Inner-Imaging Squeeze & Excitation | ‚Äî | CoRR | 2018 | []() |
| CA: Channel Attention blocks in segmentation networks | ‚Äî | ECCV | 2018‚Äì2020 | []() |
| Channel Dropout / Weighted Channel Dropout papers | ‚Äî | AAAI | 2019 | []() |
| ULSAM: Ultra-Lightweight Subspace Attention Module | ‚Äî | WACV | 2020 | []() |
| Tiled SE & Local-SE variants | ‚Äî | ICCV Workshops | 2021 | []() |
| Multi-scale channel attention (MSCAF) | ‚Äî | CVPR Workshops | 2020 | []() |
| Channel attention in GANs (Self-attention GAN variants) | H. Zhang et al. | ICML | 2019 | []() |
| Channel attention for point-cloud networks | ‚Äî | CVPR | 2019 | []() |
| Channel-wise attention for medical image segmentation (CA-Net) | L. et al. | TMI | 2021 | []() |
| Channel attention + frequency (FcaNet variants) | ‚Äî | ICCV | 2021 | []() |
| Channel-aware dynamic convolutions | ‚Äî | ECCV | 2020 | []() |
| CE-Net / Channel-enhanced modules | ‚Äî | MICCAI / TMI | 2018‚Äì2021 | []() |
| Plug-and-play channel modules summary | ‚Äî | Repo / Survey | 2020 | []() |
| Misc. channel-attention applications (detection/pose) | ‚Äî | Various | 2018‚Äì2022 | []() |

---
# Spatial Attention ‚Äî Awesome Attention

Papers that learn to attend over spatial regions (where to look).

| Title | Authors | Venue | Year | Paper Link |
|---|---|---:|---:|---|
| Recurrent Models of Visual Attention | V. Mnih, N. Heess, A. Graves, K. Kavukcuoglu | NeurIPS | 2014 | []() |
| Show, Attend and Tell: Neural Image Caption Generation with Visual Attention | K. Xu et al. | ICML | 2015 | []() |
| Spatial Transformer Networks | M. Jaderberg et al. | NeurIPS | 2015 | []() |
| DRAW: A Recurrent Neural Network for Image Generation | K. Gregor et al. | ICML | 2015 | []() |
| Attention U-Net: Learning Where to Look for the Pancreas | O. Oktay et al. | MIDL | 2018 | []() |
| Non-local Neural Networks | X. Wang et al. | CVPR | 2018 | []() |
| Attention Augmented Convolutional Networks | A. Parmar et al. | ICCV | 2019 | []() |
| Psanet: Point-wise Spatial Attention Network for Scene Parsing | ‚Äî | ECCV | 2018 | []() |
| A2-Nets: Double Attention Networks | Z. et al. | NeurIPS | 2018 | []() |
| Look Closer to See Better (RA-CNN) | S. Fu et al. | CVPR | 2017 | []() |
| Attentional Pooling for Action Recognition | R. et al. | NeurIPS | 2017 | []() |
| Visual Attention for Fine-grained Recognition (various) | ‚Äî | ICCV/CVPR | 2016‚Äì2019 | []() |
| Attention in Image Captioning (various improvements) | ‚Äî | ICCV/CVPR | 2015‚Äì2020 | []() |
| Attention-Aware Compositional Networks for Re-ID | ‚Äî | CVPR | 2018 | []() |
| Tell Me Where to Look: Guided Attention Inference Network | ‚Äî | CVPR | 2018 | []() |
| Attentional ShapeContextNet for Point Cloud Recognition | ‚Äî | CVPR | 2018 | []() |
| Attentional PointNet for 3D detection | ‚Äî | CVPRW | 2019 | []() |
| Human attention in VQA studies (human vs model) | A. Das et al. | CVIU | 2017 | []() |
| Supervising Attention with Human Gaze for Video Captioning | Y. Yu et al. | CVPR | 2017 | []() |
| Non-local operations & variants | ‚Äî | CVPR / ECCV | 2018‚Äì2020 | []() |
| Attention Correctness in Image Captioning | C. Liu et al. | AAAI | 2017 | []() |
| Guided Attention for Detection/Counting (GANet) | ‚Äî | ACM MM | 2020 | []() |
| Attention for Video Summarization | J. Fajtl et al. | ACCV | 2018 | []() |
| Local Relation / Relation Networks for Recognition | ‚Äî | ICCV/CVPR | 2019 | []() |
| Second-order attention models for VQA | ‚Äî | NeurIPS | 2017 | []() |
| Attention for Person Re-ID (diverse) | ‚Äî | CVPR/ICCV | 2017‚Äì2020 | []() |
| Attention-guided convolution for thorax disease classification | ‚Äî | arXiv | 2019 | []() |
| Self-Attention GANs (spatial attention in GANs) | H. Zhang et al. | ICML | 2019 | []() |
| Spatial attention in point-cloud & 3D tasks | ‚Äî | ICCV / CVPR | 2019‚Äì2021 | []() |
| Misc spatial-attention improvements and surveys | ‚Äî | Various | 2015‚Äì2022 | []() |
---

# Temporal Attention ‚Äî Awesome Attention

Papers focused on attention in time series, video, and other temporal sequences.

| Title | Authors | Venue | Year | Paper Link |
|---|---|---:|---:|---|
| Jointly Attentive Spatial-Temporal Pooling Networks | ‚Äî | ICCV | 2017 | []() |
| VideoLSTM: Convolves, Attends and Flows for Action Recognition | ‚Äî | arXiv | 2016 | []() |
| Temporal Attention for Action Recognition (various) | ‚Äî | CVPR/ICCV | 2016‚Äì2020 | []() |
| Hierarchical LSTMs with Adaptive Attention for Visual Captioning | ‚Äî | TPAMI | 2020 | []() |
| Space-time Mixing Attention for Video Transformer | ‚Äî | CoRR | 2021 | []() |
| Temporal attention-augmented bilinear network (finance) | D. T. Tran et al. | TNNLS | 2019 | []() |
| Video summary via attention (Summarizing videos with attention) | J. Fajtl et al. | ACCV | 2018 | []() |
| Temporal Self-Attention in Transformers for Video | ‚Äî | CVPR/ICCV | 2020‚Äì2022 | []() |
| Multi-scale temporal attention for action detection | ‚Äî | ECCV / CVPR | 2018‚Äì2021 | []() |
| Temporal co-attention for video QA | ‚Äî | NeurIPS / ICCV | 2018‚Äì2020 | []() |
| Temporal attention in speech + audio (ASR integration) | ‚Äî | ICASSP | 2015‚Äì2019 | []() |
| Video person re-identification with temporal attention | ‚Äî | CVPR | 2018 | []() |
| Temporal attention for multi-object tracking | ‚Äî | CVPR | 2019 | []() |
| Multi-hop temporal attention for reasoning across time | ‚Äî | ACL / NAACL | 2018‚Äì2020 | []() |
| Transformer-based temporal models (TimeSformer, etc.) | ‚Äî | ICCV/CVPR | 2021 | []() |
| Temporal attention for ECG / clinical time series (Attend & Diagnose) | H. Song et al. | AAAI | 2018 | []() |
| Temporal attention for video person reid (snippet aggregation) | ‚Äî | CVPR | 2018 | []() |
| Video captioning with temporal attention | L. Gao et al. | TMM | 2017 | []() |
| Temporal attention for video segmentation | ‚Äî | CVPR | 2020 | []() |
| Temporal attention networks for audio tagging | Y. Xu et al. | Interspeech | 2017 | []() |
| Spatio-temporal attention for re-id and tracking | ‚Äî | ICCV / ECCV | 2017‚Äì2021 | []() |
| Temporal attention for anomaly detection in videos | ‚Äî | CVPR Workshops | 2019‚Äì2021 | []() |
| Temporal attention for multimodal fusion (AVSR) | T. Afouras et al. | TPAMI | 2018 | []() |
| Temporal attention for forecasting (finance & sensors) | ‚Äî | TNNLS / ICML workshops | 2019‚Äì2021 | []() |
| Temporal attention in video transformers (TimeSformer variants) | ‚Äî | ICCV / CVPR | 2021 | []() |
| RNN + attention for sequence-to-sequence tasks (classic) | D. Bahdanau et al. | ICLR | 2015 | []() |
| Multi-head temporal attention adaptations | ‚Äî | NeurIPS / ICLR | 2018‚Äì2021 | []() |
| Temporal attention for audio-visual event localization | ‚Äî | ACM MM | 2019 | []() |
| Misc temporal-attention literature & benchmarks | ‚Äî | Various | 2016‚Äì2022 | []() |

---

# Channel + Spatial Attention ‚Äî Awesome Attention

Hybrid modules that combine both channel and spatial attention.

| Title | Authors | Venue | Year | Paper Link |
|---|---|---:|---:|---|
| CBAM: Convolutional Block Attention Module | S. Woo et al. | ECCV | 2018 | []() |
| BAM: Bottleneck Attention Module | J. Park et al. | BMVC | 2018 | []() |
| Residual Attention Network for Image Classification | F. Wang et al. | CVPR | 2017 | []() |
| SCA-CNN: Spatial and Channel-wise attention | ‚Äî | CVPR | 2017 | []() |
| DANet: Dual Attention Network for Scene Segmentation | J. Fu et al. | CVPR | 2019 | []() |
| Coordinate Attention | Q. Hou et al. | CVPR | 2021 | []() |
| scSE: Concurrent Spatial & Channel SE (medical) | ‚Äî | MICCAI | 2018 | []() |
| Triplet Attention (convolutional triplet) | ‚Äî | WACV | 2021 | []() |
| AFF: Attentional Feature Fusion | ‚Äî | WACV | 2021 | []() |
| PSANet: Point-wise Spatial Attention Network (channel+spatial variants) | ‚Äî | ECCV | 2018 | []() |
| Residual attention U-Nets (medical) | ‚Äî | MICCAI / MIDL | 2018‚Äì2021 | []() |
| Recalibrating FCNs with scSE blocks | ‚Äî | TMI | 2018 | []() |
| Attention U-Net (channel + spatial gating) | O. Oktay et al. | MIDL | 2018 | []() |
| CBAM variants & improvements | ‚Äî | CVPR Workshops | 2019‚Äì2021 | []() |
| Coordinate Attention for Mobile Networks | ‚Äî | CVPR | 2021 | []() |
| NAM: Normalization-based Attention Module | ‚Äî | CoRR | 2021 | []() |
| EPSANet: Efficient Pyramid Split Attention Block | ‚Äî | CoRR | 2021 | []() |
| SimAM: Parameter-free attention for CNNs | ‚Äî | ICML | 2021 | []() |
| SIAM / SPA modules combining channel+spatial | ‚Äî | ICCV / ECCV | 2019‚Äì2021 | []() |
| STN+SE hybrid modules | ‚Äî | CVPR Workshops | 2019 | []() |
| Res2Net with attention (channel+spatial injections) | ‚Äî | CVPR | 2019 | []() |
| Cross-channel communication networks | ‚Äî | NeurIPS | 2019 | []() |
| CCNet: Criss-Cross Attention (spatial with reweighting) | ‚Äî | ICCV | 2019 | []() |
| A2-Nets: Double attention (channel+spatial interaction) | ‚Äî | NeurIPS | 2018 | []() |
| HAttMatting: Attention for matting (channel+spatial) | ‚Äî | CVPR | 2020 | []() |
| AW-Conv: Attention as convolutional activation | ‚Äî | ICCV | 2021 | []() |
| CA-Net: Comprehensive Attention for Explainable Med Seg | L. et al. | TMI | 2021 | []() |
| SRM + spatial fusion modules | ‚Äî | ICCV | 2019‚Äì2020 | []() |
| Plug-and-play joint attention blocks (PP-NAS etc.) | ‚Äî | ICCV Workshops | 2021 | []() |
| Misc channel+spatial hybrid works | ‚Äî | Various | 2017‚Äì2022 | []() |

---

# Transformer-based Attention ‚Äî Awesome Attention

Self-attention and transformer architectures for NLP, vision, and multi-modal tasks.

| Title | Authors | Venue | Year | Paper Link |
|---|---|---:|---:|---|
| Attention Is All You Need | A. Vaswani et al. | NeurIPS | 2017 | []() |
| Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context | Z. Dai et al. | ACL | 2019 | []() |
| Reformer: The Efficient Transformer | N. Kitaev et al. | ICLR | 2020 | []() |
| Linformer: Self-attention with Linear Complexity | S. Wang et al. | arXiv | 2020 | []() |
| Longformer / BigBird (sparse attention) | I. Zaheer et al. / A. Joshi et al. | ACL / NeurIPS | 2020 | []() |
| ViT: An Image is Worth 16x16 Words | A. Dosovitskiy et al. | ICLR | 2021 | []() |
| Swin Transformer: Hierarchical Vision Transformer using Shifted Windows | Z. Liu et al. | ICCV | 2021 | []() |
| DeiT: Data-efficient Image Transformers | Touvron et al. | ICML | 2021 | []() |
| CoAtNet: Marrying Convolution and Attention | ‚Äî | CoRR | 2021 | []() |
| CaiT / CPVT / ConViT variants | ‚Äî | ICCV / CoRR | 2021 | []() |
| MaxViT: Multi-Axis Vision Transformer | ‚Äî | CoRR | 2022 | []() |
| Reformer / Performer / Linformer family | Various | ICLR / NeurIPS | 2020‚Äì2022 | []() |
| DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification | ‚Äî | NeurIPS | 2021 | []() |
| DVT: Dynamic Transformers for Efficient Image Recognition | ‚Äî | NeurIPS | 2021 | []() |
| LocalViT / MobileViT / LeViT (efficient ViTs) | ‚Äî | CoRR | 2021 | []() |
| BEiT / MAE / Self-supervised ViT pretraining | ‚Äî | CVPR / ICLR | 2021‚Äì2022 | []() |
| DeiT distillation & data-efficient training | Touvron et al. | ICML | 2021 | []() |
| Vision Transformer with Deformable Attention (DAT) | ‚Äî | CoRR | 2022 | []() |
| ConvNeXt / ConvNeXt-V2 discussions on conv vs attention | ‚Äî | CoRR | 2022‚Äì2023 | []() |
| VOLO / VOLO variants (vision outlookers) | ‚Äî | CoRR | 2021 | []() |
| Transformer in Transformer / TNT | ‚Äî | arXiv | 2021 | []() |
| Query2Label / Masked-attention classification variants | ‚Äî | arXiv | 2021 | []() |
| Synthesizer: Rethinking Self-Attention | Y. Tay et al. | ICML | 2021 | []() |
| Efficient Transformers: A Survey | Y. Tay et al. | arXiv | 2020 | []() |
| Reformer / Performer / Linformer comparisons | ‚Äî | Surveys | 2020‚Äì2022 | []() |
| Dynamic token pruning & token sparsification works | ‚Äî | NeurIPS / ICLR | 2021‚Äì2022 | []() |
| IO: Image-specific transformer optimizations (various) | ‚Äî | CVPR/ICCV | 2021‚Äì2023 | []() |
| SEG: Segmentation transformer models (SegFormer, etc.) | ‚Äî | ECCV / CVPR | 2021 | []() |
| SAM: Segment Anything (foundation vision model using attention) | Meta AI | CoRR | 2023 | []() |

---

# Graph Attention ‚Äî Awesome Attention

Attention mechanisms applied to graph-structured data (GNNs).

| Title | Authors | Venue | Year | Paper Link |
|---|---|---:|---:|---|
| Graph Attention Networks (GAT) | P. Veliƒçkoviƒá et al. | ICLR | 2018 | []() |
| GATv2: Adaptive Graph Attention | ‚Äî | arXiv | 2021 | []() |
| Graph Attention Network variants & surveys | ‚Äî | TKDD / CoRR | 2019‚Äì2021 | []() |
| LatentGNN: Learning efficient non-local relations | S. Zhang et al. | ICML | 2019 | []() |
| Graph-based global reasoning networks | ‚Äî | CVPR | 2019 | []() |
| Factor Graph Attention | ‚Äî | CVPR | 2019 | []() |
| Graph Transformer Network (GTN) family | ‚Äî | NeurIPS / ICLR | 2020‚Äì2022 | []() |
| Dynamic Graph Attention (Dysat) | A. Sankar et al. | WSDM | 2020 | []() |
| Attention models in graphs: A survey | J. B. Lee et al. | TKDD | 2019 | []() |
| Graph attention for recommender systems (GAT-based) | ‚Äî | KDD | 2018‚Äì2020 | []() |
| Heterogeneous graph attention networks (HAN) | ‚Äî | WWW / KDD | 2019 | []() |
| Multi-head graph attention & normalization techniques | ‚Äî | ICLR | 2019‚Äì2021 | []() |
| Graph attention for molecular property prediction | ‚Äî | NeurIPS / ICML | 2018‚Äì2021 | []() |
| Attention over edges & edge-aware GAT variations | ‚Äî | ICLR / ICML | 2019‚Äì2022 | []() |
| Graph attention for dynamic graphs & streaming | ‚Äî | WSDM / KDD | 2020‚Äì2022 | []() |
| Inductive graph attention approaches (GraphSAGE+attn) | ‚Äî | NeurIPS | 2017‚Äì2019 | []() |
| Graph attention for protein folding / bio tasks | ‚Äî | Bioinformatics venues | 2019‚Äì2022 | []() |
| Graph co-attention for multi-graph reasoning | ‚Äî | ACL / EMNLP | 2019‚Äì2021 | []() |
| Graph attention for knowledge graphs (KGAT-like) | ‚Äî | WWW / KDD | 2019 | []() |
| Scalable graph attention for large graphs (sampling) | ‚Äî | KDD / WSDM | 2020 | []() |
| Graph attention in traffic forecasting & spatio-temporal GNNs | ‚Äî | AAAI / NeurIPS | 2019‚Äì2021 | []() |
| Graph attention for 3D point clouds & meshes | ‚Äî | ICCV / CVPR | 2019‚Äì2021 | []() |
| Graph attention & fairness/explainability works | ‚Äî | FAT* / ICLR | 2020‚Äì2022 | []() |
| Graph attention for social network analysis & fake news detection | Y.-J. Lu et al. | ACL | 2020 | []() |
| Graph attention + transformers (Graphormer etc.) | ‚Äî | NeurIPS | 2021 | []() |
| Attention pooling & readout mechanisms for graphs | ‚Äî | ICML / ICLR | 2018‚Äì2021 | []() |
| Benchmarking graph attention models (surveys) | ‚Äî | Surveys | 2020‚Äì2022 | []() |
| Graph attention for recommender systems (multi-pointer co-attention) | Y. Tay et al. | KDD | 2018 | []() |
| Misc graph-attention advances & code repos | ‚Äî | Various | 2018‚Äì2022 | []() |

---

# Speech & Audio Attention ‚Äî Awesome Attention

Attention in ASR, audio tagging, speaker recognition, and audio-visual speech.

| Title | Authors | Venue | Year | Paper Link |
|---|---|---:|---:|---|
| Neural Machine Translation by Jointly Learning to Align and Translate | D. Bahdanau et al. | ICLR | 2015 | []() |
| Attention-based Models for Speech Recognition | J. Chorowski et al. | NeurIPS | 2015 | []() |
| End-to-end attention-based large vocabulary speech recognition | D. Bahdanau et al. | ICASSP | 2016 | []() |
| Joint CTC-Attention based End-to-end Speech Recognition | S. Kim et al. | ICASSP | 2017 | []() |
| Very Deep Self-Attention Networks for End-to-End Speech Recognition | N.-Q. Pham et al. | arXiv | 2019 | []() |
| Deep Audio-Visual Speech Recognition | T. Afouras et al. | TPAMI / 2018 | 2018 | []() |
| Self-attention networks for connectionist temporal classification | J. Salazar et al. | ICASSP | 2019 | []() |
| Multi-level attention model for weakly supervised audio classification | C. Yu et al. | DCASE Workshop | 2018 | []() |
| Attention and localization for audio tagging | Y. Xu et al. | Interspeech | 2017 | []() |
| Self multi-head attention for speaker recognition | M. India et al. | Interspeech | 2019 | []() |
| Attention for speech emotion recognition (multi-hop) | S. Yoon et al. | ICASSP | 2019 | []() |
| Transformer-based ASR models (Speech-Transformer) | L. Dong et al. | ICASSP | 2018 | []() |
| Self-attention for long-range speech modeling (Transformer-XL variants) | ‚Äî | ICASSP / Interspeech | 2019‚Äì2021 | []() |
| Auditory scene analysis with attention models | ‚Äî | DCASE / ICASSP | 2018‚Äì2020 | []() |
| Attention in speaker diarization & separation | ‚Äî | ICASSP / Interspeech | 2019‚Äì2021 | []() |
| Multi-modal attention for AVSR & lipreading | ‚Äî | ICASSP / TPAMI | 2018‚Äì2021 | []() |
| Attention for keyword spotting & wake-word detection | ‚Äî | Interspeech | 2019 | []() |
| Attention in speech enhancement & denoising | ‚Äî | ICASSP | 2019‚Äì2022 | []() |
| Attention-based audio retrieval & tagging | ‚Äî | ACM MM | 2018‚Äì2019 | []() |
| Attention-based music recommendation & tagging | ‚Äî | ISMIR | 2018‚Äì2020 | []() |
| Attention for low-resource ASR & transfer learning | ‚Äî | Interspeech | 2019 | []() |
| Attention + CTC hybrids & multi-task models | ‚Äî | ICASSP | 2017‚Äì2020 | []() |
| Attention in speech synthesis (TTS) | ‚Äî | ICASSP / NeurIPS | 2018‚Äì2021 | []() |
| Attention for phoneme recognition & alignment | P. Schwarz et al. | TSD | 2004 | []() |
| Attention for speaker verification & spoofing detection | ‚Äî | Interspeech | 2019‚Äì2021 | []() |
| Attention-based ASR benchmarks & surveys | ‚Äî | Surveys | 2018‚Äì2021 | []() |
| Attention and localization based on deep convolutional recurrent models | Y. Xu et al. | Interspeech | 2017 | []() |
| Self-supervised attention pretraining for audio | ‚Äî | ICML / NeurIPS | 2020‚Äì2022 | []() |
| Misc speech/audio attention works & toolkits | ‚Äî | Various | 2015‚Äì2022 | []() |

---

# Multi-modal Attention ‚Äî Awesome Attention

Cross-modal and co-attention for tasks combining vision + language / audio + vision.

| Title | Authors | Venue | Year | Paper Link |
|---|---|---:|---:|---|
| Bottom-Up and Top-Down Attention for Image Captioning & VQA | P. Anderson et al. | CVPR | 2018 | []() |
| Hierarchical Question-Image Co-Attention for VQA | J. Lu et al. | NeurIPS | 2016 | []() |
| Meshed-Memory Transformer for Image Captioning | M. Cornia et al. | CVPR | 2020 | []() |
| VisualBERT / LXMERT / ViLBERT (vision-language transformers) | ‚Äî | ACL / NeurIPS | 2019‚Äì2020 | []() |
| Co-attention Memory Networks for Diagnosis Prediction | J. Gao et al. | ICDM | 2019 | []() |
| Multi-pointer Co-Attention Networks for Recommendation | Y. Tay et al. | KDD | 2018 | []() |
| Image-text retrieval with cross-attention | ‚Äî | CVPR / ECCV | 2018‚Äì2021 | []() |
| Cross-attention for few-shot classification (cross-attn) | R. Hou et al. | NeurIPS | 2019 | []() |
| Bottom-up features + co-attention for VQA improvements | ‚Äî | CVPR | 2018 | []() |
| Meshed-memory & meshed decoder improvements | ‚Äî | CVPR | 2020 | []() |
| Attention for visual dialog & multi-turn QA | ‚Äî | ACL / EMNLP | 2018‚Äì2020 | []() |
| Dual attention / co-attention networks for multi-modal fusion | ‚Äî | CVPR / ICCV | 2017‚Äì2020 | []() |
| Audio-visual speech recognition (AVSR) with attention | T. Afouras et al. | TPAMI | 2018 | []() |
| Attention for multi-modal retrieval (images & video) | ‚Äî | ACM MM | 2018‚Äì2021 | []() |
| Multi-modal transformers (Video+Text) | ‚Äî | ACL / CVPR | 2020‚Äì2022 | []() |
| Cross-modal attention for referring expression comprehension | ‚Äî | CVPR | 2019‚Äì2021 | []() |
| Co-attention memory networks for healthcare diagnosis | J. Gao et al. | ICDM | 2019 | []() |
| Co-attention for person re-identification (multi-modal inputs) | ‚Äî | ECCV / CVPR | 2018‚Äì2021 | []() |
| Visual grounding & cross-attention approaches | ‚Äî | ICCV / CVPR | 2019 | []() |
| Attention for image captioning (multi-modal attention stacks) | K. Xu et al. | ICML | 2015 | []() |
| Cross-attention for speech+text fusion (ASR+LM) | ‚Äî | ICASSP / ACL | 2019‚Äì2021 | []() |
| Multi-modal attention for robotics & perception | ‚Äî | ICRA / IROS | 2019‚Äì2021 | []() |
| Cross-attention for multi-lingual vision-language tasks | ‚Äî | ACL / EMNLP | 2019‚Äì2021 | []() |
| Co-attention & cross-modal retrieval benchmarks | ‚Äî | Datasets/Workshops | 2019‚Äì2021 | []() |
| Attention-based multi-modal transformers for video understanding | ‚Äî | CVPR / ICCV | 2020‚Äì2022 | []() |
| Multimodal pretraining with attention objectives | ‚Äî | NeurIPS / ICML | 2020‚Äì2022 | []() |
| Cross-modal contrastive learning with attention | ‚Äî | NeurIPS / ICML | 2020‚Äì2022 | []() |
| Query2Label & other label-attention classification works | ‚Äî | arXiv | 2021 | []() |
| Misc multi-modal attention works & toolkits | ‚Äî | Various | 2015‚Äì2022 | []() |

---









